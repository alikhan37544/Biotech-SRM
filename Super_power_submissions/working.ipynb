{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>LogEE_A</th>\n",
       "      <th>VE1_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.001104</td>\n",
       "      <td>2.501652</td>\n",
       "      <td>4.923679</td>\n",
       "      <td>25.001104</td>\n",
       "      <td>1.250055</td>\n",
       "      <td>3.907976</td>\n",
       "      <td>3.763026</td>\n",
       "      <td>...</td>\n",
       "      <td>9.918524</td>\n",
       "      <td>67.526731</td>\n",
       "      <td>284.075684</td>\n",
       "      <td>8.877365</td>\n",
       "      <td>764.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.274271</td>\n",
       "      <td>2.409184</td>\n",
       "      <td>4.779725</td>\n",
       "      <td>20.274271</td>\n",
       "      <td>1.267142</td>\n",
       "      <td>3.699349</td>\n",
       "      <td>3.675755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.636588</td>\n",
       "      <td>61.986524</td>\n",
       "      <td>226.038985</td>\n",
       "      <td>9.827782</td>\n",
       "      <td>429.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>3.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.679070</td>\n",
       "      <td>2.528665</td>\n",
       "      <td>4.931112</td>\n",
       "      <td>23.679070</td>\n",
       "      <td>1.392886</td>\n",
       "      <td>3.823524</td>\n",
       "      <td>3.787841</td>\n",
       "      <td>...</td>\n",
       "      <td>10.022647</td>\n",
       "      <td>65.026165</td>\n",
       "      <td>223.074562</td>\n",
       "      <td>8.579791</td>\n",
       "      <td>461.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.774585</td>\n",
       "      <td>2.557762</td>\n",
       "      <td>4.967131</td>\n",
       "      <td>27.774585</td>\n",
       "      <td>1.388729</td>\n",
       "      <td>4.000936</td>\n",
       "      <td>4.113451</td>\n",
       "      <td>...</td>\n",
       "      <td>10.250228</td>\n",
       "      <td>70.773493</td>\n",
       "      <td>266.069142</td>\n",
       "      <td>8.868971</td>\n",
       "      <td>735.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.613943</td>\n",
       "      <td>2.477563</td>\n",
       "      <td>4.835703</td>\n",
       "      <td>39.613943</td>\n",
       "      <td>1.320465</td>\n",
       "      <td>4.331178</td>\n",
       "      <td>4.133872</td>\n",
       "      <td>...</td>\n",
       "      <td>10.233043</td>\n",
       "      <td>79.537169</td>\n",
       "      <td>415.183067</td>\n",
       "      <td>7.548783</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.162228</td>\n",
       "      <td>2.444418</td>\n",
       "      <td>4.888835</td>\n",
       "      <td>25.162228</td>\n",
       "      <td>1.324328</td>\n",
       "      <td>3.885650</td>\n",
       "      <td>3.788230</td>\n",
       "      <td>...</td>\n",
       "      <td>9.911108</td>\n",
       "      <td>52.566001</td>\n",
       "      <td>259.120843</td>\n",
       "      <td>7.197801</td>\n",
       "      <td>688.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>4.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.266178</td>\n",
       "      <td>2.534987</td>\n",
       "      <td>4.934272</td>\n",
       "      <td>25.266178</td>\n",
       "      <td>1.203151</td>\n",
       "      <td>3.960779</td>\n",
       "      <td>3.746040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.024155</td>\n",
       "      <td>69.315801</td>\n",
       "      <td>328.076075</td>\n",
       "      <td>8.633581</td>\n",
       "      <td>904.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>4.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.921252</td>\n",
       "      <td>2.296174</td>\n",
       "      <td>4.541085</td>\n",
       "      <td>23.921252</td>\n",
       "      <td>1.259013</td>\n",
       "      <td>3.850677</td>\n",
       "      <td>3.853332</td>\n",
       "      <td>...</td>\n",
       "      <td>9.488048</td>\n",
       "      <td>65.073826</td>\n",
       "      <td>278.094980</td>\n",
       "      <td>8.427121</td>\n",
       "      <td>813.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6.305556</td>\n",
       "      <td>4.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.341681</td>\n",
       "      <td>2.541818</td>\n",
       "      <td>5.014881</td>\n",
       "      <td>35.341681</td>\n",
       "      <td>1.359295</td>\n",
       "      <td>4.226118</td>\n",
       "      <td>4.327006</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356186</td>\n",
       "      <td>75.559148</td>\n",
       "      <td>352.169939</td>\n",
       "      <td>7.492977</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.179816</td>\n",
       "      <td>2.416831</td>\n",
       "      <td>4.706367</td>\n",
       "      <td>31.179816</td>\n",
       "      <td>1.299159</td>\n",
       "      <td>4.102321</td>\n",
       "      <td>3.801567</td>\n",
       "      <td>...</td>\n",
       "      <td>9.878324</td>\n",
       "      <td>73.901759</td>\n",
       "      <td>361.077950</td>\n",
       "      <td>9.258409</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.277778</td>\n",
       "      <td>5.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 1524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cls  nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A     SpAD_A   SpMAD_A  \\\n",
       "0     1.0    0.0    0.0  25.001104  2.501652  4.923679  25.001104  1.250055   \n",
       "1     1.0    0.0    0.0  20.274271  2.409184  4.779725  20.274271  1.267142   \n",
       "2     1.0    0.0    0.0  23.679070  2.528665  4.931112  23.679070  1.392886   \n",
       "3     1.0    0.0    0.0  27.774585  2.557762  4.967131  27.774585  1.388729   \n",
       "4     1.0    0.0    0.0  39.613943  2.477563  4.835703  39.613943  1.320465   \n",
       "...   ...    ...    ...        ...       ...       ...        ...       ...   \n",
       "7995  0.0    0.0    1.0  25.162228  2.444418  4.888835  25.162228  1.324328   \n",
       "7996  0.0    0.0    0.0  25.266178  2.534987  4.934272  25.266178  1.203151   \n",
       "7997  0.0    2.0    0.0  23.921252  2.296174  4.541085  23.921252  1.259013   \n",
       "7998  0.0    0.0    0.0  35.341681  2.541818  5.014881  35.341681  1.359295   \n",
       "7999  0.0    0.0    0.0  31.179816  2.416831  4.706367  31.179816  1.299159   \n",
       "\n",
       "       LogEE_A     VE1_A  ...      SRW10     TSRW10          MW       AMW  \\\n",
       "0     3.907976  3.763026  ...   9.918524  67.526731  284.075684  8.877365   \n",
       "1     3.699349  3.675755  ...   9.636588  61.986524  226.038985  9.827782   \n",
       "2     3.823524  3.787841  ...  10.022647  65.026165  223.074562  8.579791   \n",
       "3     4.000936  4.113451  ...  10.250228  70.773493  266.069142  8.868971   \n",
       "4     4.331178  4.133872  ...  10.233043  79.537169  415.183067  7.548783   \n",
       "...        ...       ...  ...        ...        ...         ...       ...   \n",
       "7995  3.885650  3.788230  ...   9.911108  52.566001  259.120843  7.197801   \n",
       "7996  3.960779  3.746040  ...  10.024155  69.315801  328.076075  8.633581   \n",
       "7997  3.850677  3.853332  ...   9.488048  65.073826  278.094980  8.427121   \n",
       "7998  4.226118  4.327006  ...  10.356186  75.559148  352.169939  7.492977   \n",
       "7999  4.102321  3.801567  ...   9.878324  73.901759  361.077950  9.258409   \n",
       "\n",
       "       WPath  WPol  Zagreb1  Zagreb2  mZagreb1  mZagreb2  \n",
       "0      764.0  32.0    100.0    119.0  7.777778  4.666667  \n",
       "1      429.0  23.0     82.0     96.0  6.166667  3.583333  \n",
       "2      461.0  29.0     98.0    121.0  3.416667  3.638889  \n",
       "3      735.0  35.0    120.0    150.0  3.888889  4.166667  \n",
       "4     2674.0  45.0    156.0    182.0  8.500000  6.694444  \n",
       "...      ...   ...      ...      ...       ...       ...  \n",
       "7995   688.0  30.0    100.0    118.0  5.416667  4.194444  \n",
       "7996   904.0  34.0    108.0    128.0  9.250000  4.611111  \n",
       "7997   813.0  23.0     92.0    103.0  6.305556  4.361111  \n",
       "7998  1547.0  44.0    146.0    177.0  6.000000  5.583333  \n",
       "7999  1515.0  32.0    122.0    141.0  7.277778  5.416667  \n",
       "\n",
       "[8000 rows x 1524 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>LogEE_A</th>\n",
       "      <th>VE1_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.216375</td>\n",
       "      <td>0.207625</td>\n",
       "      <td>32.946519</td>\n",
       "      <td>2.439413</td>\n",
       "      <td>4.821464</td>\n",
       "      <td>32.946519</td>\n",
       "      <td>1.283254</td>\n",
       "      <td>4.140275</td>\n",
       "      <td>4.151293</td>\n",
       "      <td>...</td>\n",
       "      <td>10.087755</td>\n",
       "      <td>70.558406</td>\n",
       "      <td>369.020966</td>\n",
       "      <td>8.234841</td>\n",
       "      <td>3.034145e+08</td>\n",
       "      <td>39.683000</td>\n",
       "      <td>134.377500</td>\n",
       "      <td>157.565500</td>\n",
       "      <td>8.403843</td>\n",
       "      <td>5.706780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500031</td>\n",
       "      <td>0.581033</td>\n",
       "      <td>0.522304</td>\n",
       "      <td>8.159715</td>\n",
       "      <td>0.084997</td>\n",
       "      <td>0.157726</td>\n",
       "      <td>8.159715</td>\n",
       "      <td>0.041261</td>\n",
       "      <td>0.242455</td>\n",
       "      <td>0.398093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354882</td>\n",
       "      <td>10.814510</td>\n",
       "      <td>90.908842</td>\n",
       "      <td>1.215813</td>\n",
       "      <td>2.208319e+09</td>\n",
       "      <td>12.728895</td>\n",
       "      <td>35.566594</td>\n",
       "      <td>43.518918</td>\n",
       "      <td>2.445272</td>\n",
       "      <td>1.402642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.857279</td>\n",
       "      <td>2.067601</td>\n",
       "      <td>4.135202</td>\n",
       "      <td>10.857279</td>\n",
       "      <td>1.031389</td>\n",
       "      <td>3.143082</td>\n",
       "      <td>2.769185</td>\n",
       "      <td>...</td>\n",
       "      <td>8.384119</td>\n",
       "      <td>38.654211</td>\n",
       "      <td>138.042927</td>\n",
       "      <td>4.766344</td>\n",
       "      <td>1.030000e+02</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.894977</td>\n",
       "      <td>2.379068</td>\n",
       "      <td>4.716589</td>\n",
       "      <td>27.894977</td>\n",
       "      <td>1.254209</td>\n",
       "      <td>3.976687</td>\n",
       "      <td>3.888416</td>\n",
       "      <td>...</td>\n",
       "      <td>9.874496</td>\n",
       "      <td>62.928355</td>\n",
       "      <td>307.135063</td>\n",
       "      <td>7.448129</td>\n",
       "      <td>1.062000e+03</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>6.777778</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.081803</td>\n",
       "      <td>2.434977</td>\n",
       "      <td>4.810872</td>\n",
       "      <td>32.081803</td>\n",
       "      <td>1.286372</td>\n",
       "      <td>4.143182</td>\n",
       "      <td>4.108821</td>\n",
       "      <td>...</td>\n",
       "      <td>10.103649</td>\n",
       "      <td>71.200214</td>\n",
       "      <td>362.195405</td>\n",
       "      <td>8.078691</td>\n",
       "      <td>1.736500e+03</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>8.090278</td>\n",
       "      <td>5.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.678261</td>\n",
       "      <td>2.491846</td>\n",
       "      <td>4.914689</td>\n",
       "      <td>37.678261</td>\n",
       "      <td>1.313001</td>\n",
       "      <td>4.304722</td>\n",
       "      <td>4.391835</td>\n",
       "      <td>...</td>\n",
       "      <td>10.313990</td>\n",
       "      <td>78.042672</td>\n",
       "      <td>420.149718</td>\n",
       "      <td>8.797475</td>\n",
       "      <td>2.727000e+03</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>9.638889</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>96.779823</td>\n",
       "      <td>2.872317</td>\n",
       "      <td>5.589818</td>\n",
       "      <td>96.779823</td>\n",
       "      <td>1.398412</td>\n",
       "      <td>5.262114</td>\n",
       "      <td>6.606666</td>\n",
       "      <td>...</td>\n",
       "      <td>11.517624</td>\n",
       "      <td>134.866641</td>\n",
       "      <td>1111.641665</td>\n",
       "      <td>37.199571</td>\n",
       "      <td>8.410000e+10</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>34.805556</td>\n",
       "      <td>17.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cls        nAcid        nBase      SpAbs_A      SpMax_A  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      0.500000     0.216375     0.207625    32.946519     2.439413   \n",
       "std       0.500031     0.581033     0.522304     8.159715     0.084997   \n",
       "min       0.000000     0.000000     0.000000    10.857279     2.067601   \n",
       "25%       0.000000     0.000000     0.000000    27.894977     2.379068   \n",
       "50%       0.500000     0.000000     0.000000    32.081803     2.434977   \n",
       "75%       1.000000     0.000000     0.000000    37.678261     2.491846   \n",
       "max       1.000000     5.000000     5.000000    96.779823     2.872317   \n",
       "\n",
       "          SpDiam_A       SpAD_A      SpMAD_A      LogEE_A        VE1_A  ...  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  ...   \n",
       "mean      4.821464    32.946519     1.283254     4.140275     4.151293  ...   \n",
       "std       0.157726     8.159715     0.041261     0.242455     0.398093  ...   \n",
       "min       4.135202    10.857279     1.031389     3.143082     2.769185  ...   \n",
       "25%       4.716589    27.894977     1.254209     3.976687     3.888416  ...   \n",
       "50%       4.810872    32.081803     1.286372     4.143182     4.108821  ...   \n",
       "75%       4.914689    37.678261     1.313001     4.304722     4.391835  ...   \n",
       "max       5.589818    96.779823     1.398412     5.262114     6.606666  ...   \n",
       "\n",
       "             SRW10       TSRW10           MW          AMW         WPath  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8.000000e+03   \n",
       "mean     10.087755    70.558406   369.020966     8.234841  3.034145e+08   \n",
       "std       0.354882    10.814510    90.908842     1.215813  2.208319e+09   \n",
       "min       8.384119    38.654211   138.042927     4.766344  1.030000e+02   \n",
       "25%       9.874496    62.928355   307.135063     7.448129  1.062000e+03   \n",
       "50%      10.103649    71.200214   362.195405     8.078691  1.736500e+03   \n",
       "75%      10.313990    78.042672   420.149718     8.797475  2.727000e+03   \n",
       "max      11.517624   134.866641  1111.641665    37.199571  8.410000e+10   \n",
       "\n",
       "              WPol      Zagreb1      Zagreb2     mZagreb1     mZagreb2  \n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  \n",
       "mean     39.683000   134.377500   157.565500     8.403843     5.706780  \n",
       "std      12.728895    35.566594    43.518918     2.445272     1.402642  \n",
       "min       6.000000    36.000000    39.000000     2.222222     1.861111  \n",
       "25%      31.000000   110.000000   128.000000     6.777778     4.750000  \n",
       "50%      38.000000   132.000000   154.000000     8.090278     5.611111  \n",
       "75%      46.000000   154.000000   182.000000     9.638889     6.500000  \n",
       "max     137.000000   398.000000   466.000000    34.805556    17.611111  \n",
       "\n",
       "[8 rows x 1524 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Columns: 1524 entries, cls to mZagreb2\n",
      "dtypes: float64(1524)\n",
      "memory usage: 93.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1524)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier,n_estimators=50,random_state=42)\n",
    "adaboost_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSummary : \\nTrying to train with a progress bar doesn't seem to work. Without any \\n1. TQDM took forever to run, said 1 hour 30 minutes for 50 iterations\\n2. Even a simple for loop took forever to run\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Summary : \n",
    "Trying to train with a progress bar doesn't seem to work. Without any \n",
    "1. TQDM took forever to run, said 1 hour 30 minutes for 50 iterations\n",
    "2. Even a simple for loop took forever to run\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# # Create the base classifier\n",
    "# base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# # Create the AdaBoost classifier without a progress bar\n",
    "# n_estimators = 50\n",
    "# adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "# # Train the AdaBoost classifier with progress updates\n",
    "# for i in range(n_estimators):\n",
    "#     adaboost_classifier.fit(X_train, y_train)\n",
    "#     print(f\"Training AdaBoost: {i+1}/{n_estimators} completed\")\n",
    "\n",
    "\n",
    "## For some reason even a simple AdaBoostClassifier is taking forever to run\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# print(\"Modules Imported\")\n",
    "\n",
    "# # Create the base classifier\n",
    "# base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# print(\"Base classifier created\")\n",
    "\n",
    "# # Create the AdaBoost classifier without a progress bar\n",
    "# n_estimators = 50\n",
    "# adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "# print(\"Adaboost classifier created\")\n",
    "\n",
    "# # Set the interval for progress updates\n",
    "# progress_interval = 5  # Adjust this interval as needed\n",
    "\n",
    "# print(\"Progress interval also created\")\n",
    "\n",
    "# # Train the AdaBoost classifier with progress updates\n",
    "# for i in range(n_estimators):\n",
    "#     adaboost_classifier.fit(X_train, y_train)\n",
    "#     if (i + 1) % progress_interval == 0 or i == n_estimators - 1:\n",
    "#         print(f\"Training AdaBoost: {i + 1}/{n_estimators} completed\")\n",
    "\n",
    "# # Now, your AdaBoost classifier is trained with periodic progress updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82875\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.84      0.83       796\n",
      "         1.0       0.84      0.82      0.83       804\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.83      0.83      0.83      1600\n",
      "weighted avg       0.83      0.83      0.83      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = adaboost_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "report = classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Classification report\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv\")\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "preceptron = Perceptron(max_iter=1000,random_state=42)\n",
    "preceptron.fit(X_train,y_train)\n",
    "\n",
    "y_pred = preceptron.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.516875\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.866875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "data = pd.read_csv(\"G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv\")\n",
    "\n",
    "X = data.drop(\"cls\",axis=1)\n",
    "y= data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=100,learning_rate=0.1,max_depth=3,random_state=42)\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.773125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\",axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "decision = DecisionTreeClassifier()\n",
    "decision.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tejha) \n",
    "# First Round of analysis\n",
    "\n",
    "Adaboost accuracy : 0.82875\n",
    "Preceptron accuracy : 0.53\n",
    "SVM accuracy : 0.51\n",
    "GBM accuracy : 0.866875\n",
    "Naive Bayes accuracy : 0.7625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ali)\n",
    "# First Round of analysis\n",
    "\n",
    "Same except for Naive Bayes : 0.773125\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Stage: Kfold\n",
    "\n",
    "We are going to do Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8418750000000002\n"
     ]
    }
   ],
   "source": [
    "# Adaboost Kfolded\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "folds = 5\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    adaboost_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = adaboost_classifier.predict(X_val_fold)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / folds\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.5055000000000001\n"
     ]
    }
   ],
   "source": [
    "# Preceptron Kfold\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preceptron = Perceptron(max_iter=1000,random_state=42)\n",
    "\n",
    "folds = 5\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    preceptron.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = preceptron.predict(X_val_fold)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / folds\n",
    "print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.5141249999999999\n"
     ]
    }
   ],
   "source": [
    "# SVM Kfold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "folds = 5\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    svm.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = svm.predict(X_val_fold)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / folds\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8723749999999999\n"
     ]
    }
   ],
   "source": [
    "# GBM Kfold\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=100,learning_rate=0.1,max_depth=3,random_state=42)\n",
    "\n",
    "folds = 5\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    gbm.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = gbm.predict(X_val_fold)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / folds\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.790875\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Kfold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "decision = DecisionTreeClassifier()\n",
    "\n",
    "folds = 5\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    decision.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = decision.predict(X_val_fold)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / folds\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Stage: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for adaboost: {'learning_rate': 0.5, 'n_estimators': 150}\n",
      "Best Accuracy Score for adaboost: 0.850375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':[50,100,150],\n",
    "    'learning_rate':[0.1,0.5,1.0],\n",
    "}\n",
    "\n",
    "adaboostgridsearch = GridSearchCV(adaboost_classifier,param_grid,cv=5,scoring='accuracy')\n",
    "adaboostgridsearch.fit(X, y)\n",
    "\n",
    "adaboostbest_params = adaboostgridsearch.best_params_\n",
    "adaboostbest_score = adaboostgridsearch.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters for adaboost:\", adaboostbest_params)\n",
    "print(\"Best Accuracy Score for adaboost:\", adaboostbest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for GBM: {'learning_rate': 0.5, 'n_estimators': 100}\n",
      "Best Accuracy Score for GBM: 0.859125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':[50,100,150],\n",
    "    'learning_rate':[0.1,0.5,1.0],\n",
    "}\n",
    "\n",
    "GBMgridsearch = GridSearchCV(gbm,param_grid,cv=5,scoring='accuracy')\n",
    "GBMgridsearch.fit(X, y) \n",
    "\n",
    "GBMbest_params = GBMgridsearch.best_params_\n",
    "GBMbest_score = GBMgridsearch.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters for GBM:\", GBMbest_params)\n",
    "print(\"Best Accuracy Score for GBM:\", GBMbest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Stage: Kfold and Grid search code combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress: 5it [18:57, 227.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8622500000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "best_hyperparameters = {'learning_rate': 0.5, 'n_estimators': 150}\n",
    "\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X), desc=\"Cross-Validation Progress\", position=0, leave=True):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    adaboost_classifier = AdaBoostClassifier(**best_hyperparameters, random_state=42)\n",
    "    adaboost_classifier.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = adaboost_classifier.predict(X_val_fold)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / folds\n",
    "print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress: 5it [54:30, 654.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8797499999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "data = pd.read_csv('G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv')\n",
    "\n",
    "X = data.drop(\"cls\", axis=1)\n",
    "y = data[\"cls\"]\n",
    "\n",
    "best_hyperparameters = {'learning_rate': 0.5, 'n_estimators': 150}\n",
    "\n",
    "gbm = GradientBoostingClassifier(**best_hyperparameters, max_depth=3, random_state=42)\n",
    "\n",
    "folds = 5\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(X), desc=\"Cross-Validation Progress\", position=0, leave=True):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    gbm.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = gbm.predict(X_val_fold)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_scores) / folds\n",
    "print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"G:\\My Drive\\Programming\\Biotech Research Project\\imputed_testset.csv\")\n",
    "data_train = pd.read_csv(\"G:\\My Drive\\Programming\\Biotech Research Project\\imputed_trainset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>LogEE_A</th>\n",
       "      <th>VE1_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.088019</td>\n",
       "      <td>2.445165</td>\n",
       "      <td>4.890329</td>\n",
       "      <td>27.088019</td>\n",
       "      <td>1.231274</td>\n",
       "      <td>4.001574</td>\n",
       "      <td>3.958514</td>\n",
       "      <td>...</td>\n",
       "      <td>10.032189</td>\n",
       "      <td>56.149665</td>\n",
       "      <td>323.099143</td>\n",
       "      <td>8.077479</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>8.979167</td>\n",
       "      <td>4.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.050045</td>\n",
       "      <td>2.328086</td>\n",
       "      <td>4.614018</td>\n",
       "      <td>37.050045</td>\n",
       "      <td>1.277588</td>\n",
       "      <td>4.276564</td>\n",
       "      <td>4.773032</td>\n",
       "      <td>...</td>\n",
       "      <td>9.990720</td>\n",
       "      <td>77.406545</td>\n",
       "      <td>428.097683</td>\n",
       "      <td>8.736687</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.138889</td>\n",
       "      <td>6.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.096537</td>\n",
       "      <td>2.450210</td>\n",
       "      <td>4.747965</td>\n",
       "      <td>32.096537</td>\n",
       "      <td>1.283861</td>\n",
       "      <td>4.142878</td>\n",
       "      <td>3.746826</td>\n",
       "      <td>...</td>\n",
       "      <td>9.975576</td>\n",
       "      <td>75.253570</td>\n",
       "      <td>372.071468</td>\n",
       "      <td>9.074914</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>8.138889</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.263137</td>\n",
       "      <td>2.460053</td>\n",
       "      <td>4.890810</td>\n",
       "      <td>45.263137</td>\n",
       "      <td>1.293232</td>\n",
       "      <td>4.479404</td>\n",
       "      <td>4.901285</td>\n",
       "      <td>...</td>\n",
       "      <td>10.388595</td>\n",
       "      <td>86.901917</td>\n",
       "      <td>531.115018</td>\n",
       "      <td>8.566371</td>\n",
       "      <td>3487.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>11.583333</td>\n",
       "      <td>7.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.807444</td>\n",
       "      <td>2.482121</td>\n",
       "      <td>4.964016</td>\n",
       "      <td>43.807444</td>\n",
       "      <td>1.288454</td>\n",
       "      <td>4.452201</td>\n",
       "      <td>4.590124</td>\n",
       "      <td>...</td>\n",
       "      <td>10.429547</td>\n",
       "      <td>83.429320</td>\n",
       "      <td>494.106706</td>\n",
       "      <td>8.668539</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>10.812500</td>\n",
       "      <td>7.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.493319</td>\n",
       "      <td>2.560954</td>\n",
       "      <td>4.961716</td>\n",
       "      <td>33.493319</td>\n",
       "      <td>1.288205</td>\n",
       "      <td>4.211626</td>\n",
       "      <td>4.261202</td>\n",
       "      <td>...</td>\n",
       "      <td>10.336211</td>\n",
       "      <td>77.646669</td>\n",
       "      <td>350.149124</td>\n",
       "      <td>7.957935</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>8.722222</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.532270</td>\n",
       "      <td>2.515849</td>\n",
       "      <td>5.010027</td>\n",
       "      <td>43.532270</td>\n",
       "      <td>1.360383</td>\n",
       "      <td>4.432917</td>\n",
       "      <td>5.019092</td>\n",
       "      <td>...</td>\n",
       "      <td>10.548363</td>\n",
       "      <td>83.988899</td>\n",
       "      <td>454.178710</td>\n",
       "      <td>7.830667</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>6.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.355652</td>\n",
       "      <td>2.347966</td>\n",
       "      <td>4.578227</td>\n",
       "      <td>30.355652</td>\n",
       "      <td>1.319811</td>\n",
       "      <td>4.054484</td>\n",
       "      <td>3.717367</td>\n",
       "      <td>...</td>\n",
       "      <td>9.689118</td>\n",
       "      <td>70.143152</td>\n",
       "      <td>308.138559</td>\n",
       "      <td>7.900989</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.805556</td>\n",
       "      <td>5.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.980227</td>\n",
       "      <td>2.358732</td>\n",
       "      <td>4.706855</td>\n",
       "      <td>29.980227</td>\n",
       "      <td>1.303488</td>\n",
       "      <td>4.062206</td>\n",
       "      <td>4.424915</td>\n",
       "      <td>...</td>\n",
       "      <td>9.877195</td>\n",
       "      <td>70.580534</td>\n",
       "      <td>332.141930</td>\n",
       "      <td>7.724231</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>7.027778</td>\n",
       "      <td>5.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.253679</td>\n",
       "      <td>2.358133</td>\n",
       "      <td>4.604629</td>\n",
       "      <td>24.253679</td>\n",
       "      <td>1.276509</td>\n",
       "      <td>3.851181</td>\n",
       "      <td>3.699661</td>\n",
       "      <td>...</td>\n",
       "      <td>9.567385</td>\n",
       "      <td>65.600707</td>\n",
       "      <td>261.091355</td>\n",
       "      <td>8.422302</td>\n",
       "      <td>783.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.305556</td>\n",
       "      <td>4.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cls  nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A     SpAD_A   SpMAD_A  \\\n",
       "0     1.0    0.0    0.0  27.088019  2.445165  4.890329  27.088019  1.231274   \n",
       "1     1.0    0.0    0.0  37.050045  2.328086  4.614018  37.050045  1.277588   \n",
       "2     1.0    0.0    2.0  32.096537  2.450210  4.747965  32.096537  1.283861   \n",
       "3     1.0    0.0    0.0  45.263137  2.460053  4.890810  45.263137  1.293232   \n",
       "4     1.0    0.0    0.0  43.807444  2.482121  4.964016  43.807444  1.288454   \n",
       "...   ...    ...    ...        ...       ...       ...        ...       ...   \n",
       "1995  0.0    0.0    0.0  33.493319  2.560954  4.961716  33.493319  1.288205   \n",
       "1996  0.0    2.0    1.0  43.532270  2.515849  5.010027  43.532270  1.360383   \n",
       "1997  0.0    2.0    0.0  30.355652  2.347966  4.578227  30.355652  1.319811   \n",
       "1998  0.0    0.0    0.0  29.980227  2.358732  4.706855  29.980227  1.303488   \n",
       "1999  0.0    0.0    0.0  24.253679  2.358133  4.604629  24.253679  1.276509   \n",
       "\n",
       "       LogEE_A     VE1_A  ...      SRW10     TSRW10          MW       AMW  \\\n",
       "0     4.001574  3.958514  ...  10.032189  56.149665  323.099143  8.077479   \n",
       "1     4.276564  4.773032  ...   9.990720  77.406545  428.097683  8.736687   \n",
       "2     4.142878  3.746826  ...   9.975576  75.253570  372.071468  9.074914   \n",
       "3     4.479404  4.901285  ...  10.388595  86.901917  531.115018  8.566371   \n",
       "4     4.452201  4.590124  ...  10.429547  83.429320  494.106706  8.668539   \n",
       "...        ...       ...  ...        ...        ...         ...       ...   \n",
       "1995  4.211626  4.261202  ...  10.336211  77.646669  350.149124  7.957935   \n",
       "1996  4.432917  5.019092  ...  10.548363  83.988899  454.178710  7.830667   \n",
       "1997  4.054484  3.717367  ...   9.689118  70.143152  308.138559  7.900989   \n",
       "1998  4.062206  4.424915  ...   9.877195  70.580534  332.141930  7.724231   \n",
       "1999  3.851181  3.699661  ...   9.567385  65.600707  261.091355  8.422302   \n",
       "\n",
       "       WPath  WPol  Zagreb1  Zagreb2   mZagreb1  mZagreb2  \n",
       "0     1090.0  35.0    112.0    130.0   8.979167  4.875000  \n",
       "1     2803.0  39.0    144.0    163.0   9.138889  6.611111  \n",
       "2     1688.0  35.0    128.0    149.0   8.138889  5.555556  \n",
       "3     3487.0  54.0    182.0    214.0  11.583333  7.777778  \n",
       "4     3362.0  53.0    178.0    208.0  10.812500  7.416667  \n",
       "...      ...   ...      ...      ...        ...       ...  \n",
       "1995  1505.0  44.0    144.0    175.0   8.722222  5.555556  \n",
       "1996  2700.0  54.0    180.0    219.0   7.222222  6.888889  \n",
       "1997  1475.0  28.0    114.0    128.0   5.805556  5.194444  \n",
       "1998  1371.0  32.0    118.0    136.0   7.027778  5.138889  \n",
       "1999   783.0  25.0     92.0    105.0   6.305556  4.472222  \n",
       "\n",
       "[2000 rows x 1514 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>LogEE_A</th>\n",
       "      <th>VE1_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.001104</td>\n",
       "      <td>2.501652</td>\n",
       "      <td>4.923679</td>\n",
       "      <td>25.001104</td>\n",
       "      <td>1.250055</td>\n",
       "      <td>3.907976</td>\n",
       "      <td>3.763026</td>\n",
       "      <td>...</td>\n",
       "      <td>9.918524</td>\n",
       "      <td>67.526731</td>\n",
       "      <td>284.075684</td>\n",
       "      <td>8.877365</td>\n",
       "      <td>764.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.274271</td>\n",
       "      <td>2.409184</td>\n",
       "      <td>4.779725</td>\n",
       "      <td>20.274271</td>\n",
       "      <td>1.267142</td>\n",
       "      <td>3.699349</td>\n",
       "      <td>3.675755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.636588</td>\n",
       "      <td>61.986524</td>\n",
       "      <td>226.038985</td>\n",
       "      <td>9.827782</td>\n",
       "      <td>429.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>3.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.679070</td>\n",
       "      <td>2.528665</td>\n",
       "      <td>4.931112</td>\n",
       "      <td>23.679070</td>\n",
       "      <td>1.392886</td>\n",
       "      <td>3.823524</td>\n",
       "      <td>3.787841</td>\n",
       "      <td>...</td>\n",
       "      <td>10.022647</td>\n",
       "      <td>65.026165</td>\n",
       "      <td>223.074562</td>\n",
       "      <td>8.579791</td>\n",
       "      <td>461.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.774585</td>\n",
       "      <td>2.557762</td>\n",
       "      <td>4.967131</td>\n",
       "      <td>27.774585</td>\n",
       "      <td>1.388729</td>\n",
       "      <td>4.000936</td>\n",
       "      <td>4.113451</td>\n",
       "      <td>...</td>\n",
       "      <td>10.250228</td>\n",
       "      <td>70.773493</td>\n",
       "      <td>266.069142</td>\n",
       "      <td>8.868971</td>\n",
       "      <td>735.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.613943</td>\n",
       "      <td>2.477563</td>\n",
       "      <td>4.835703</td>\n",
       "      <td>39.613943</td>\n",
       "      <td>1.320465</td>\n",
       "      <td>4.331178</td>\n",
       "      <td>4.133872</td>\n",
       "      <td>...</td>\n",
       "      <td>10.233043</td>\n",
       "      <td>79.537169</td>\n",
       "      <td>415.183067</td>\n",
       "      <td>7.548783</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.162228</td>\n",
       "      <td>2.444418</td>\n",
       "      <td>4.888835</td>\n",
       "      <td>25.162228</td>\n",
       "      <td>1.324328</td>\n",
       "      <td>3.885650</td>\n",
       "      <td>3.788230</td>\n",
       "      <td>...</td>\n",
       "      <td>9.911108</td>\n",
       "      <td>52.566001</td>\n",
       "      <td>259.120843</td>\n",
       "      <td>7.197801</td>\n",
       "      <td>688.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>4.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.266178</td>\n",
       "      <td>2.534987</td>\n",
       "      <td>4.934272</td>\n",
       "      <td>25.266178</td>\n",
       "      <td>1.203151</td>\n",
       "      <td>3.960779</td>\n",
       "      <td>3.746040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.024155</td>\n",
       "      <td>69.315801</td>\n",
       "      <td>328.076075</td>\n",
       "      <td>8.633581</td>\n",
       "      <td>904.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>4.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.921252</td>\n",
       "      <td>2.296174</td>\n",
       "      <td>4.541085</td>\n",
       "      <td>23.921252</td>\n",
       "      <td>1.259013</td>\n",
       "      <td>3.850677</td>\n",
       "      <td>3.853332</td>\n",
       "      <td>...</td>\n",
       "      <td>9.488048</td>\n",
       "      <td>65.073826</td>\n",
       "      <td>278.094980</td>\n",
       "      <td>8.427121</td>\n",
       "      <td>813.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6.305556</td>\n",
       "      <td>4.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.341681</td>\n",
       "      <td>2.541818</td>\n",
       "      <td>5.014881</td>\n",
       "      <td>35.341681</td>\n",
       "      <td>1.359295</td>\n",
       "      <td>4.226118</td>\n",
       "      <td>4.327006</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356186</td>\n",
       "      <td>75.559148</td>\n",
       "      <td>352.169939</td>\n",
       "      <td>7.492977</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.179816</td>\n",
       "      <td>2.416831</td>\n",
       "      <td>4.706367</td>\n",
       "      <td>31.179816</td>\n",
       "      <td>1.299159</td>\n",
       "      <td>4.102321</td>\n",
       "      <td>3.801567</td>\n",
       "      <td>...</td>\n",
       "      <td>9.878324</td>\n",
       "      <td>73.901759</td>\n",
       "      <td>361.077950</td>\n",
       "      <td>9.258409</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.277778</td>\n",
       "      <td>5.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 1524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cls  nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A     SpAD_A   SpMAD_A  \\\n",
       "0     1.0    0.0    0.0  25.001104  2.501652  4.923679  25.001104  1.250055   \n",
       "1     1.0    0.0    0.0  20.274271  2.409184  4.779725  20.274271  1.267142   \n",
       "2     1.0    0.0    0.0  23.679070  2.528665  4.931112  23.679070  1.392886   \n",
       "3     1.0    0.0    0.0  27.774585  2.557762  4.967131  27.774585  1.388729   \n",
       "4     1.0    0.0    0.0  39.613943  2.477563  4.835703  39.613943  1.320465   \n",
       "...   ...    ...    ...        ...       ...       ...        ...       ...   \n",
       "7995  0.0    0.0    1.0  25.162228  2.444418  4.888835  25.162228  1.324328   \n",
       "7996  0.0    0.0    0.0  25.266178  2.534987  4.934272  25.266178  1.203151   \n",
       "7997  0.0    2.0    0.0  23.921252  2.296174  4.541085  23.921252  1.259013   \n",
       "7998  0.0    0.0    0.0  35.341681  2.541818  5.014881  35.341681  1.359295   \n",
       "7999  0.0    0.0    0.0  31.179816  2.416831  4.706367  31.179816  1.299159   \n",
       "\n",
       "       LogEE_A     VE1_A  ...      SRW10     TSRW10          MW       AMW  \\\n",
       "0     3.907976  3.763026  ...   9.918524  67.526731  284.075684  8.877365   \n",
       "1     3.699349  3.675755  ...   9.636588  61.986524  226.038985  9.827782   \n",
       "2     3.823524  3.787841  ...  10.022647  65.026165  223.074562  8.579791   \n",
       "3     4.000936  4.113451  ...  10.250228  70.773493  266.069142  8.868971   \n",
       "4     4.331178  4.133872  ...  10.233043  79.537169  415.183067  7.548783   \n",
       "...        ...       ...  ...        ...        ...         ...       ...   \n",
       "7995  3.885650  3.788230  ...   9.911108  52.566001  259.120843  7.197801   \n",
       "7996  3.960779  3.746040  ...  10.024155  69.315801  328.076075  8.633581   \n",
       "7997  3.850677  3.853332  ...   9.488048  65.073826  278.094980  8.427121   \n",
       "7998  4.226118  4.327006  ...  10.356186  75.559148  352.169939  7.492977   \n",
       "7999  4.102321  3.801567  ...   9.878324  73.901759  361.077950  9.258409   \n",
       "\n",
       "       WPath  WPol  Zagreb1  Zagreb2  mZagreb1  mZagreb2  \n",
       "0      764.0  32.0    100.0    119.0  7.777778  4.666667  \n",
       "1      429.0  23.0     82.0     96.0  6.166667  3.583333  \n",
       "2      461.0  29.0     98.0    121.0  3.416667  3.638889  \n",
       "3      735.0  35.0    120.0    150.0  3.888889  4.166667  \n",
       "4     2674.0  45.0    156.0    182.0  8.500000  6.694444  \n",
       "...      ...   ...      ...      ...       ...       ...  \n",
       "7995   688.0  30.0    100.0    118.0  5.416667  4.194444  \n",
       "7996   904.0  34.0    108.0    128.0  9.250000  4.611111  \n",
       "7997   813.0  23.0     92.0    103.0  6.305556  4.361111  \n",
       "7998  1547.0  44.0    146.0    177.0  6.000000  5.583333  \n",
       "7999  1515.0  32.0    122.0    141.0  7.277778  5.416667  \n",
       "\n",
       "[8000 rows x 1524 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I have data_train and data_test. i have trained all my ml models on the data_train and now i want to predict the cls for data_test. However, I have 10 extra columns in data_train.\n",
    "# # I need to add those 10 columns to data_test and then predict the cls for data_test\n",
    "\n",
    "# data_train.columns\n",
    "\n",
    "# data_test.columns\n",
    "\n",
    "# data_train.columns.difference(data_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to fill the missing columns with the data_train columns\n",
    "\n",
    "# data_test = data_test.reindex(columns=data_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>LogEE_A</th>\n",
       "      <th>VE1_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.088019</td>\n",
       "      <td>2.445165</td>\n",
       "      <td>4.890329</td>\n",
       "      <td>27.088019</td>\n",
       "      <td>1.231274</td>\n",
       "      <td>4.001574</td>\n",
       "      <td>3.958514</td>\n",
       "      <td>...</td>\n",
       "      <td>10.032189</td>\n",
       "      <td>56.149665</td>\n",
       "      <td>323.099143</td>\n",
       "      <td>8.077479</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>8.979167</td>\n",
       "      <td>4.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.050045</td>\n",
       "      <td>2.328086</td>\n",
       "      <td>4.614018</td>\n",
       "      <td>37.050045</td>\n",
       "      <td>1.277588</td>\n",
       "      <td>4.276564</td>\n",
       "      <td>4.773032</td>\n",
       "      <td>...</td>\n",
       "      <td>9.990720</td>\n",
       "      <td>77.406545</td>\n",
       "      <td>428.097683</td>\n",
       "      <td>8.736687</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.138889</td>\n",
       "      <td>6.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.096537</td>\n",
       "      <td>2.450210</td>\n",
       "      <td>4.747965</td>\n",
       "      <td>32.096537</td>\n",
       "      <td>1.283861</td>\n",
       "      <td>4.142878</td>\n",
       "      <td>3.746826</td>\n",
       "      <td>...</td>\n",
       "      <td>9.975576</td>\n",
       "      <td>75.253570</td>\n",
       "      <td>372.071468</td>\n",
       "      <td>9.074914</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>8.138889</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.263137</td>\n",
       "      <td>2.460053</td>\n",
       "      <td>4.890810</td>\n",
       "      <td>45.263137</td>\n",
       "      <td>1.293232</td>\n",
       "      <td>4.479404</td>\n",
       "      <td>4.901285</td>\n",
       "      <td>...</td>\n",
       "      <td>10.388595</td>\n",
       "      <td>86.901917</td>\n",
       "      <td>531.115018</td>\n",
       "      <td>8.566371</td>\n",
       "      <td>3487.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>11.583333</td>\n",
       "      <td>7.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.807444</td>\n",
       "      <td>2.482121</td>\n",
       "      <td>4.964016</td>\n",
       "      <td>43.807444</td>\n",
       "      <td>1.288454</td>\n",
       "      <td>4.452201</td>\n",
       "      <td>4.590124</td>\n",
       "      <td>...</td>\n",
       "      <td>10.429547</td>\n",
       "      <td>83.429320</td>\n",
       "      <td>494.106706</td>\n",
       "      <td>8.668539</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>10.812500</td>\n",
       "      <td>7.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.493319</td>\n",
       "      <td>2.560954</td>\n",
       "      <td>4.961716</td>\n",
       "      <td>33.493319</td>\n",
       "      <td>1.288205</td>\n",
       "      <td>4.211626</td>\n",
       "      <td>4.261202</td>\n",
       "      <td>...</td>\n",
       "      <td>10.336211</td>\n",
       "      <td>77.646669</td>\n",
       "      <td>350.149124</td>\n",
       "      <td>7.957935</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>8.722222</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.532270</td>\n",
       "      <td>2.515849</td>\n",
       "      <td>5.010027</td>\n",
       "      <td>43.532270</td>\n",
       "      <td>1.360383</td>\n",
       "      <td>4.432917</td>\n",
       "      <td>5.019092</td>\n",
       "      <td>...</td>\n",
       "      <td>10.548363</td>\n",
       "      <td>83.988899</td>\n",
       "      <td>454.178710</td>\n",
       "      <td>7.830667</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>6.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.355652</td>\n",
       "      <td>2.347966</td>\n",
       "      <td>4.578227</td>\n",
       "      <td>30.355652</td>\n",
       "      <td>1.319811</td>\n",
       "      <td>4.054484</td>\n",
       "      <td>3.717367</td>\n",
       "      <td>...</td>\n",
       "      <td>9.689118</td>\n",
       "      <td>70.143152</td>\n",
       "      <td>308.138559</td>\n",
       "      <td>7.900989</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.805556</td>\n",
       "      <td>5.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.980227</td>\n",
       "      <td>2.358732</td>\n",
       "      <td>4.706855</td>\n",
       "      <td>29.980227</td>\n",
       "      <td>1.303488</td>\n",
       "      <td>4.062206</td>\n",
       "      <td>4.424915</td>\n",
       "      <td>...</td>\n",
       "      <td>9.877195</td>\n",
       "      <td>70.580534</td>\n",
       "      <td>332.141930</td>\n",
       "      <td>7.724231</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>7.027778</td>\n",
       "      <td>5.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.253679</td>\n",
       "      <td>2.358133</td>\n",
       "      <td>4.604629</td>\n",
       "      <td>24.253679</td>\n",
       "      <td>1.276509</td>\n",
       "      <td>3.851181</td>\n",
       "      <td>3.699661</td>\n",
       "      <td>...</td>\n",
       "      <td>9.567385</td>\n",
       "      <td>65.600707</td>\n",
       "      <td>261.091355</td>\n",
       "      <td>8.422302</td>\n",
       "      <td>783.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.305556</td>\n",
       "      <td>4.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cls  nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A     SpAD_A   SpMAD_A  \\\n",
       "0     1.0    0.0    0.0  27.088019  2.445165  4.890329  27.088019  1.231274   \n",
       "1     1.0    0.0    0.0  37.050045  2.328086  4.614018  37.050045  1.277588   \n",
       "2     1.0    0.0    2.0  32.096537  2.450210  4.747965  32.096537  1.283861   \n",
       "3     1.0    0.0    0.0  45.263137  2.460053  4.890810  45.263137  1.293232   \n",
       "4     1.0    0.0    0.0  43.807444  2.482121  4.964016  43.807444  1.288454   \n",
       "...   ...    ...    ...        ...       ...       ...        ...       ...   \n",
       "1995  0.0    0.0    0.0  33.493319  2.560954  4.961716  33.493319  1.288205   \n",
       "1996  0.0    2.0    1.0  43.532270  2.515849  5.010027  43.532270  1.360383   \n",
       "1997  0.0    2.0    0.0  30.355652  2.347966  4.578227  30.355652  1.319811   \n",
       "1998  0.0    0.0    0.0  29.980227  2.358732  4.706855  29.980227  1.303488   \n",
       "1999  0.0    0.0    0.0  24.253679  2.358133  4.604629  24.253679  1.276509   \n",
       "\n",
       "       LogEE_A     VE1_A  ...      SRW10     TSRW10          MW       AMW  \\\n",
       "0     4.001574  3.958514  ...  10.032189  56.149665  323.099143  8.077479   \n",
       "1     4.276564  4.773032  ...   9.990720  77.406545  428.097683  8.736687   \n",
       "2     4.142878  3.746826  ...   9.975576  75.253570  372.071468  9.074914   \n",
       "3     4.479404  4.901285  ...  10.388595  86.901917  531.115018  8.566371   \n",
       "4     4.452201  4.590124  ...  10.429547  83.429320  494.106706  8.668539   \n",
       "...        ...       ...  ...        ...        ...         ...       ...   \n",
       "1995  4.211626  4.261202  ...  10.336211  77.646669  350.149124  7.957935   \n",
       "1996  4.432917  5.019092  ...  10.548363  83.988899  454.178710  7.830667   \n",
       "1997  4.054484  3.717367  ...   9.689118  70.143152  308.138559  7.900989   \n",
       "1998  4.062206  4.424915  ...   9.877195  70.580534  332.141930  7.724231   \n",
       "1999  3.851181  3.699661  ...   9.567385  65.600707  261.091355  8.422302   \n",
       "\n",
       "       WPath  WPol  Zagreb1  Zagreb2   mZagreb1  mZagreb2  \n",
       "0     1090.0  35.0    112.0    130.0   8.979167  4.875000  \n",
       "1     2803.0  39.0    144.0    163.0   9.138889  6.611111  \n",
       "2     1688.0  35.0    128.0    149.0   8.138889  5.555556  \n",
       "3     3487.0  54.0    182.0    214.0  11.583333  7.777778  \n",
       "4     3362.0  53.0    178.0    208.0  10.812500  7.416667  \n",
       "...      ...   ...      ...      ...        ...       ...  \n",
       "1995  1505.0  44.0    144.0    175.0   8.722222  5.555556  \n",
       "1996  2700.0  54.0    180.0    219.0   7.222222  6.888889  \n",
       "1997  1475.0  28.0    114.0    128.0   5.805556  5.194444  \n",
       "1998  1371.0  32.0    118.0    136.0   7.027778  5.138889  \n",
       "1999   783.0  25.0     92.0    105.0   6.305556  4.472222  \n",
       "\n",
       "[2000 rows x 1514 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are prepared to start validation on our external test set\n",
    "# we will be validating Adaboost, perceptron, SVM, GBM and Naive Bayes\n",
    "# We already have our models, all we have to do is predict with our data_test and show the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y\n",
    "\n",
    "X = data_train.drop(\"cls\", axis=1)\n",
    "y = data_train[\"cls\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = set(X_train.columns) - set(X_test.columns)\n",
    "\n",
    "for column in missing_columns:\n",
    "    X_test[column] = 0  # Set all values to zero as an example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "y_pred = adaboost_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.93      0.89       796\n",
      "         1.0       0.92      0.85      0.89       804\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.89      0.89      0.89      1600\n",
      "weighted avg       0.89      0.89      0.89      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Adaboost\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[737  59]\n",
      " [117 687]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix for Adaboost\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred),fmt=\"d\" ,annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthew's Correlation Coefficient (MCC): 0.7821310809802029\n"
     ]
    }
   ],
   "source": [
    "# Matthew's coefficient for adaboost\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the MCC score\n",
    "print(\"Matthew's Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Precision: 0.920911528150134\n",
      "Recall: 0.8544776119402985\n",
      "F1-Score: 0.8864516129032258\n",
      "AUC-ROC: 0.8901785044626116\n",
      "AUC-PR (Average Precision): 0.8600232833820175\n",
      "Matthew's Correlation Coefficient (MCC): 0.7821310809802029\n",
      "Log Loss: 3.964801872802887\n",
      "Balanced Accuracy: 0.8901785044626116\n",
      "Confusion Matrix:\n",
      "[[737  59]\n",
      " [117 687]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.93      0.89       796\n",
      "         1.0       0.92      0.85      0.89       804\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.89      0.89      0.89      1600\n",
      "weighted avg       0.89      0.89      0.89      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, matthews_corrcoef\n",
    "from sklearn.metrics import log_loss, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate predictions from your Adaboost classifier\n",
    "y_pred = adaboost_classifier.predict(X_test)\n",
    "\n",
    "# True labels are in y_test\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "\n",
    "# AUC-PR\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print(\"AUC-PR (Average Precision):\", average_precision)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthew's Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "# Log Loss\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "print(\"Log Loss:\", logloss)\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500625\n"
     ]
    }
   ],
   "source": [
    "# Perceptron predictions\n",
    "\n",
    "y_pred = preceptron.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[796   0]\n",
      " [799   5]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for Perceptron\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred),fmt=\"d\" ,annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500625\n",
      "Precision: 1.0\n",
      "Recall: 0.006218905472636816\n",
      "F1-Score: 0.012360939431396786\n",
      "AUC-ROC: 0.5031094527363185\n",
      "AUC-PR (Average Precision): 0.5055939054726368\n",
      "Matthew's Correlation Coefficient (MCC): 0.05571000121947514\n",
      "Log Loss: 17.99929941119038\n",
      "Balanced Accuracy: 0.5031094527363185\n",
      "Confusion Matrix:\n",
      "[[796   0]\n",
      " [799   5]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67       796\n",
      "         1.0       1.00      0.01      0.01       804\n",
      "\n",
      "    accuracy                           0.50      1600\n",
      "   macro avg       0.75      0.50      0.34      1600\n",
      "weighted avg       0.75      0.50      0.34      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "\n",
    "# AUC-PR\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print(\"AUC-PR (Average Precision):\", average_precision)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthew's Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "# Log Loss\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "print(\"Log Loss:\", logloss)\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.519375\n"
     ]
    }
   ],
   "source": [
    "# SVM predictions\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46 750]\n",
      " [ 19 785]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for SVM\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred),fmt=\"d\" ,annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.519375\n",
      "Precision: 0.511400651465798\n",
      "Recall: 0.9763681592039801\n",
      "F1-Score: 0.6712270200940573\n",
      "AUC-ROC: 0.5170785519637991\n",
      "AUC-PR (Average Precision): 0.5111903126873775\n",
      "Matthew's Correlation Coefficient (MCC): 0.0865076931594436\n",
      "Log Loss: 17.32348091014443\n",
      "Balanced Accuracy: 0.5170785519637991\n",
      "Confusion Matrix:\n",
      "[[ 46 750]\n",
      " [ 19 785]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.06      0.11       796\n",
      "         1.0       0.51      0.98      0.67       804\n",
      "\n",
      "    accuracy                           0.52      1600\n",
      "   macro avg       0.61      0.52      0.39      1600\n",
      "weighted avg       0.61      0.52      0.39      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "\n",
    "# AUC-PR\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print(\"AUC-PR (Average Precision):\", average_precision)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthew's Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "# Log Loss\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "print(\"Log Loss:\", logloss)\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994375\n"
     ]
    }
   ],
   "source": [
    "# GBM predictions\n",
    "\n",
    "y_pred = gbm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[796   0]\n",
      " [  9 795]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for GBM\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred),fmt=\"d\" ,annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994375\n",
      "Precision: 1.0\n",
      "Recall: 0.9888059701492538\n",
      "F1-Score: 0.9943714821763603\n",
      "AUC-ROC: 0.9944029850746269\n",
      "AUC-PR (Average Precision): 0.9944309701492537\n",
      "Matthew's Correlation Coefficient (MCC): 0.9888129229383814\n",
      "Log Loss: 0.2027455503137842\n",
      "Balanced Accuracy: 0.9944029850746269\n",
      "Confusion Matrix:\n",
      "[[796   0]\n",
      " [  9 795]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99       796\n",
      "         1.0       1.00      0.99      0.99       804\n",
      "\n",
      "    accuracy                           0.99      1600\n",
      "   macro avg       0.99      0.99      0.99      1600\n",
      "weighted avg       0.99      0.99      0.99      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "\n",
    "# AUC-PR\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print(\"AUC-PR (Average Precision):\", average_precision)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthew's Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "# Log Loss\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "print(\"Log Loss:\", logloss)\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995625\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree predictions \n",
    "\n",
    "y_pred = decision.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[796   0]\n",
      " [  7 797]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for Decision Tree\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred),fmt=\"d\" ,annot=True, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.995625\n",
      "Precision: 1.0\n",
      "Recall: 0.9912935323383084\n",
      "F1-Score: 0.9956277326670832\n",
      "AUC-ROC: 0.9956467661691542\n",
      "AUC-PR (Average Precision): 0.9956685323383084\n",
      "Matthew's Correlation Coefficient (MCC): 0.9912881111107438\n",
      "Log Loss: 0.15769098357738776\n",
      "Balanced Accuracy: 0.9956467661691542\n",
      "Confusion Matrix:\n",
      "[[796   0]\n",
      " [  7 797]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       796\n",
      "         1.0       1.00      0.99      1.00       804\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "\n",
    "# AUC-PR\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print(\"AUC-PR (Average Precision):\", average_precision)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthew's Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "# Log Loss\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "print(\"Log Loss:\", logloss)\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the 5 different models as a pickle file\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(adaboost_classifier, open(\"adaboost_classifier.pkl\", \"wb\"))\n",
    "pickle.dump(preceptron, open(\"preceptron.pkl\", \"wb\"))\n",
    "pickle.dump(svm, open(\"svm.pkl\", \"wb\"))\n",
    "pickle.dump(gbm, open(\"gbm.pkl\", \"wb\"))\n",
    "pickle.dump(decision, open(\"decision.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
